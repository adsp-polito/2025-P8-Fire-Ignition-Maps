# 2025-P8-Fire-Ignition-Maps


# ğŸ”¥ Multimodal Wildfire Burned Area Prediction

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Status](https://img.shields.io/badge/Status-Research%20Prototype-success?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

> **Abstract:** This project implements a comparative deep learning framework to evaluate whether **pre-fire multimodal data** (satellite imagery, terrain, weather, and infrastructure) can predict final wildfire burned areas more accurately than traditional Sentinel-only baselines. The study highlights the impact of **encoder design** on segmentation performance and is optimized for efficiency on **CPU-constrained environments**.

---

## ğŸ“Œ Project Objectives

The primary goals of this research are:

- **Predict** final burned areas using *only* **pre-fire information**.
- **Compare** a standard **Sentinel-only baseline** with a novel **multimodal deep learning model**.
- **Analyze** the effect of **encoder design choices** (e.g., ResNet vs. EfficientNet).
- **Estimate** the specific contribution of each **input modality** to prediction performance.
- **Produce** reproducible, slide-ready results for academic presentation.

---

## â“ Research Questions

1.  **Feasibility:** Can pre-fire multimodal data predict final burned area with sufficient accuracy to support early emergency decisions?
2.  **Optimization:** Do auxiliary objectives (e.g., land-cover segmentation) improve burned-area prediction?
3.  **Feature Importance:** Which input data modalities contribute most to predictive performance?

---

## ğŸ§  Methodology Overview

This project contrasts two modeling approaches to isolate the value of data fusion.

### 1. Baseline Model
- **Architecture:** U-Net / FPN-style segmentation
- **Input:** Sentinel-2 imagery only (12 spectral bands)
- **Encoder:** **ResNet-34** (ImageNet pretrained)
- **Purpose:** Provide a strong, interpretable reference baseline.

### 2. Multimodal Model (Final Proposed Solution)
- **Architecture:** MultiModalFPN
- **Inputs:**
  - ğŸ›°ï¸ Sentinel-2 imagery
  - ğŸ›°ï¸ Landsat imagery
  - ğŸ”ï¸ DEM + Road network rasters
  - â˜ï¸ ERA5 Weather (Raster + Tabular)
  - ğŸ”¥ Ignition point map
- **Encoder:** **EfficientNet-B4** (ImageNet pretrained)
- **Fusion:** Attention-based feature fusion blocks
- **Purpose:** Leverage complementary pre-fire signals to improve segmentation accuracy.

---

## ğŸ§© Encoder Strategy

Two encoder strategies were strictly investigated:

1.  **Multiple encoders** with different capacities for each modality.
2.  **Single unified encoder** shared across all modalities.

**Decision:** The final model adopts a **unified EfficientNet-B4 encoder**, which achieved:
- Higher **IoU** and **F1 scores**.
- More **stable training** dynamics.
- Reduced architectural complexity.

---

## ğŸ“Š Results Summary

- The multimodal model **consistently outperforms** the Sentinel-only baseline.
- Encoder choice has a **significant impact** on segmentation quality.
- Multimodal inputs provide complementary information beyond optical imagery.
- Strong performance is achieved even under **CPU-only constraints** (MacBook Air).

> *Detailed quantitative comparisons and plots are stored in the `docs/` directory.*

---


## ğŸ§ª Experimental Notes

To ensure transparency and reproducibility:

- **Hardware:** All experiments were conducted on **CPU (MacBook Air)**.
- **Optimization:** Auxiliary land-cover loss was disabled to avoid negative transfer.
- **Evaluation:** Some evaluations use reduced validation subsets for efficiency.
- **Reproducibility:** All results are clearly labeled in the `docs/` folder.

---

## âœ… Conclusion

This project shows that:

1. **Pre-fire multimodal data** can meaningfully improve burned-area prediction.
2. **Encoder design** is a critical performance factor.
3. A **unified high-capacity encoder** outperforms more complex multi-encoder setups.
4. Careful architectural choices enable strong results under **limited resources**.

---

## ğŸ‘¤ Authors

**Yousef Fayyaz**
**Parastoo Hashemi Alvar**

---

## ğŸ—‚ï¸ Project Structure

```text
WildFire/
â”‚
â”œâ”€â”€ data/                       # Raw and processed datasets
â”œâ”€â”€ geojson/                    # Vector data
â”‚
â”œâ”€â”€ docs/                       # Documentation & Analysis
â”‚   â”œâ”€â”€ Maps_Graphs/            # Generated inference maps
â”‚   â”œâ”€â”€ modality_ablation/      # Ablation study results
â”‚   â”œâ”€â”€ model_comparison/       # Baseline vs Multimodal metrics
â”‚   â”œâ”€â”€ slide_figures/          # Figures for presentation
â”‚   â””â”€â”€ output_result_paper_comparison.txt
â”‚
â”œâ”€â”€ inference/                  # Inference Scripts
â”‚   â”œâ”€â”€ compare_baseline_vs_multimodal.py
â”‚   â”œâ”€â”€ deploy_inference.py
â”‚   â”œâ”€â”€ inference_2.py
â”‚   â””â”€â”€ inference_map.py
â”‚
â”œâ”€â”€ src/                        # Source Code
â”‚   â”œâ”€â”€ Baseline_model/         # Baseline Implementation
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â”œâ”€â”€ augmentations.py
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ unet_sentinel_best.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ checkpoint_2/           # Saved Models
â”‚   â”‚   â””â”€â”€ best_model_3.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ figures_tables/         # Visualization Scripts
â”‚   â”‚   â”œâ”€â”€ export_slide_table.py
â”‚   â”‚   â”œâ”€â”€ make_qualitative_panels.py
â”‚   â”‚   â”œâ”€â”€ modality_ablation_quick.py
â”‚   â”‚   â”œâ”€â”€ paper_comparison.py
â”‚   â”‚   â””â”€â”€ plot_threshold_sweep.py
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ main.py                 # Main Training Entry Point
â”‚
â”œâ”€â”€ inference_output/
â”œâ”€â”€ runs/                       # TensorBoard Logs
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes
â””â”€â”€ readme.md



-----







